{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Module 5: Natural language processing**\n",
    "## DAT410\n",
    "\n",
    "### Group 29 \n",
    "### David Laessker, 980511-5012, laessker@chalmers.se\n",
    "\n",
    "### Oskar Palmgren, 010529-4714, oskarpal@chalmers.se\n",
    "\n",
    "\n",
    "\n",
    "We hereby declare that we have both actively participated in solving every exercise. All solutions are entirely our own work, without having taken part of other solutions.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading and reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Like speech recognition and image recognition?\n",
    "\n",
    "b) Systems that are rule-based explicitly use linguistic rules and dictionaries, while neural systems learn these linguistic patterns from large datasets. Both approaches aim to accurately translate languages by mapping structures and meanings, but through different means.\n",
    "\n",
    "c) Maybe smaller datasets? Modern neural systems may not capture the grammatical patterns in the language with scarce data. A rule based system will therefore offer more predictable and interpretable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swe_eng_file_path = 'data/europarl-v7.sv-en.lc.sv'\n",
    "eng_swe_file_path = 'data\\europarl-v7.sv-en.lc.en'\n",
    "\n",
    "ger_eng_file_path = 'data\\europarl-v7.de-en.lc.de'\n",
    "eng_ger_file_path = 'data\\europarl-v7.de-en.lc.en'\n",
    "\n",
    "fre_eng_file_path = 'data\\europarl-v7.fr-en.lc.en'\n",
    "eng_fre_file_path = 'data\\europarl-v7.fr-en.lc.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(file):\n",
    "    \n",
    "    word_counter = Counter()\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "    \n",
    "        for line in f:\n",
    "            \n",
    "            words = line.strip().split()\n",
    "            word_counter.update(words)\n",
    "    \n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 9648),\n",
       " ('att', 9181),\n",
       " (',', 8876),\n",
       " ('och', 7038),\n",
       " ('i', 5949),\n",
       " ('det', 5687),\n",
       " ('som', 5028),\n",
       " ('för', 4959),\n",
       " ('av', 4013),\n",
       " ('är', 3840)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swe_frequency = word_frequency(swe_eng_file_path)\n",
    "\n",
    "swe_top_10 = swe_frequency.most_common(10)\n",
    "\n",
    "swe_top_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 19322),\n",
       " (',', 13514),\n",
       " ('.', 9774),\n",
       " ('of', 9312),\n",
       " ('to', 8801),\n",
       " ('and', 6946),\n",
       " ('in', 6090),\n",
       " ('is', 4400),\n",
       " ('that', 4357),\n",
       " ('a', 4269)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_frequency = word_frequency(eng_swe_file_path) #maybe we should combine all the english files?\n",
    "\n",
    "eng_top_10 = eng_frequency.most_common(10)\n",
    "\n",
    "eng_top_10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove punctuations, and maybe stop words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281476\n",
      "Probability of speaker: 0.000036\n",
      "Probability of zebra: 0.0\n"
     ]
    }
   ],
   "source": [
    "eng_words_amount = sum(eng_frequency.values())\n",
    "\n",
    "#print(eng_words_amount)\n",
    "#print(eng_frequency['speaker'] )\n",
    "#print(eng_frequency['zebra'] )\n",
    "\n",
    "speaker_probability = eng_frequency['speaker'] / eng_words_amount\n",
    "zebra_probability = eng_frequency['zebra'] / eng_words_amount\n",
    "\n",
    "# calculate probability for \"speaker\" and \"zebra\" in the english text, but we need to look at all the languages?\n",
    "print(f'Probability of speaker: {speaker_probability:.6f}')\n",
    "print(f'Probability of zebra: {zebra_probability}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
