{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Local imports\n",
    "from src.collaborative_filtering import *\n",
    "#from src.database import * <--- database approach instead of memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We read x amount of playlist slices into memory\n",
    "Each contains 1000 playlists. For example, 20 slices will take about 5GB of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice 1/100: mpd.slice.0-999.json\n",
      "Processing slice 2/100: mpd.slice.1000-1999.json\n",
      "Processing slice 3/100: mpd.slice.10000-10999.json\n",
      "Processing slice 4/100: mpd.slice.100000-100999.json\n",
      "Processing slice 5/100: mpd.slice.101000-101999.json\n",
      "Processing slice 6/100: mpd.slice.102000-102999.json\n",
      "Processing slice 7/100: mpd.slice.103000-103999.json\n",
      "Processing slice 8/100: mpd.slice.104000-104999.json\n",
      "Processing slice 9/100: mpd.slice.105000-105999.json\n",
      "Processing slice 10/100: mpd.slice.106000-106999.json\n",
      "Processing slice 11/100: mpd.slice.107000-107999.json\n",
      "Processing slice 12/100: mpd.slice.108000-108999.json\n",
      "Processing slice 13/100: mpd.slice.109000-109999.json\n",
      "Processing slice 14/100: mpd.slice.11000-11999.json\n",
      "Processing slice 15/100: mpd.slice.110000-110999.json\n",
      "Processing slice 16/100: mpd.slice.111000-111999.json\n",
      "Processing slice 17/100: mpd.slice.112000-112999.json\n",
      "Processing slice 18/100: mpd.slice.113000-113999.json\n",
      "Processing slice 19/100: mpd.slice.114000-114999.json\n",
      "Processing slice 20/100: mpd.slice.115000-115999.json\n",
      "Processing slice 21/100: mpd.slice.116000-116999.json\n",
      "Processing slice 22/100: mpd.slice.117000-117999.json\n",
      "Processing slice 23/100: mpd.slice.118000-118999.json\n",
      "Processing slice 24/100: mpd.slice.119000-119999.json\n",
      "Processing slice 25/100: mpd.slice.12000-12999.json\n",
      "Processing slice 26/100: mpd.slice.120000-120999.json\n",
      "Processing slice 27/100: mpd.slice.121000-121999.json\n",
      "Processing slice 28/100: mpd.slice.122000-122999.json\n",
      "Processing slice 29/100: mpd.slice.123000-123999.json\n",
      "Processing slice 30/100: mpd.slice.124000-124999.json\n",
      "Processing slice 31/100: mpd.slice.125000-125999.json\n",
      "Processing slice 32/100: mpd.slice.126000-126999.json\n",
      "Processing slice 33/100: mpd.slice.127000-127999.json\n",
      "Processing slice 34/100: mpd.slice.128000-128999.json\n",
      "Processing slice 35/100: mpd.slice.129000-129999.json\n",
      "Processing slice 36/100: mpd.slice.13000-13999.json\n",
      "Processing slice 37/100: mpd.slice.130000-130999.json\n",
      "Processing slice 38/100: mpd.slice.131000-131999.json\n",
      "Processing slice 39/100: mpd.slice.132000-132999.json\n",
      "Processing slice 40/100: mpd.slice.133000-133999.json\n",
      "Processing slice 41/100: mpd.slice.134000-134999.json\n",
      "Processing slice 42/100: mpd.slice.135000-135999.json\n",
      "Processing slice 43/100: mpd.slice.136000-136999.json\n",
      "Processing slice 44/100: mpd.slice.137000-137999.json\n",
      "Processing slice 45/100: mpd.slice.138000-138999.json\n",
      "Processing slice 46/100: mpd.slice.139000-139999.json\n",
      "Processing slice 47/100: mpd.slice.14000-14999.json\n",
      "Processing slice 48/100: mpd.slice.140000-140999.json\n",
      "Processing slice 49/100: mpd.slice.141000-141999.json\n",
      "Processing slice 50/100: mpd.slice.142000-142999.json\n",
      "Processing slice 51/100: mpd.slice.143000-143999.json\n",
      "Processing slice 52/100: mpd.slice.144000-144999.json\n",
      "Processing slice 53/100: mpd.slice.145000-145999.json\n",
      "Processing slice 54/100: mpd.slice.146000-146999.json\n",
      "Processing slice 55/100: mpd.slice.147000-147999.json\n",
      "Processing slice 56/100: mpd.slice.148000-148999.json\n",
      "Processing slice 57/100: mpd.slice.149000-149999.json\n",
      "Processing slice 58/100: mpd.slice.15000-15999.json\n",
      "Processing slice 59/100: mpd.slice.150000-150999.json\n",
      "Processing slice 60/100: mpd.slice.151000-151999.json\n",
      "Processing slice 61/100: mpd.slice.152000-152999.json\n",
      "Processing slice 62/100: mpd.slice.153000-153999.json\n",
      "Processing slice 63/100: mpd.slice.154000-154999.json\n",
      "Processing slice 64/100: mpd.slice.155000-155999.json\n",
      "Processing slice 65/100: mpd.slice.156000-156999.json\n",
      "Processing slice 66/100: mpd.slice.157000-157999.json\n",
      "Processing slice 67/100: mpd.slice.158000-158999.json\n",
      "Processing slice 68/100: mpd.slice.159000-159999.json\n",
      "Processing slice 69/100: mpd.slice.16000-16999.json\n",
      "Processing slice 70/100: mpd.slice.160000-160999.json\n",
      "Processing slice 71/100: mpd.slice.161000-161999.json\n",
      "Processing slice 72/100: mpd.slice.162000-162999.json\n",
      "Processing slice 73/100: mpd.slice.163000-163999.json\n",
      "Processing slice 74/100: mpd.slice.164000-164999.json\n",
      "Processing slice 75/100: mpd.slice.165000-165999.json\n",
      "Processing slice 76/100: mpd.slice.166000-166999.json\n",
      "Processing slice 77/100: mpd.slice.167000-167999.json\n",
      "Processing slice 78/100: mpd.slice.168000-168999.json\n",
      "Processing slice 79/100: mpd.slice.169000-169999.json\n",
      "Processing slice 80/100: mpd.slice.17000-17999.json\n",
      "Processing slice 81/100: mpd.slice.170000-170999.json\n",
      "Processing slice 82/100: mpd.slice.171000-171999.json\n",
      "Processing slice 83/100: mpd.slice.172000-172999.json\n",
      "Processing slice 84/100: mpd.slice.173000-173999.json\n",
      "Processing slice 85/100: mpd.slice.174000-174999.json\n",
      "Processing slice 86/100: mpd.slice.175000-175999.json\n",
      "Processing slice 87/100: mpd.slice.176000-176999.json\n",
      "Processing slice 88/100: mpd.slice.177000-177999.json\n",
      "Processing slice 89/100: mpd.slice.178000-178999.json\n",
      "Processing slice 90/100: mpd.slice.179000-179999.json\n",
      "Processing slice 91/100: mpd.slice.18000-18999.json\n",
      "Processing slice 92/100: mpd.slice.180000-180999.json\n",
      "Processing slice 93/100: mpd.slice.181000-181999.json\n"
     ]
    }
   ],
   "source": [
    "folder = \"data/playlist_data/\"\n",
    "co_occurences = update_co_occurrences_from_folder(folder, slice_limit=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We create a playlists for testing recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"90s Playlist\"\n",
    "\n",
    "playlist_1 = [\n",
    "    (\"Smash Mouth\" ,\"All Star\"),\n",
    "    (\"Rick Astley\", \"Never Gonna Give You Up\"),\n",
    "    (\"The Proclaimers\", \"I'm Gonna Be (500 Miles)\"),\n",
    "    (\"Backstreet Boys\", \"I Want It That Way\"),\n",
    "    (\"The Killers\", \"Mr. Brightside\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journey - Don't Stop Believin' - 0.14326923700397048\n",
      "Dexys Midnight Runners - Come On Eileen - 0.12021304008227918\n",
      "Queen - Bohemian Rhapsody - Remastered 2011 - 0.10991054384754884\n",
      "Smash Mouth - All Star - 0.09869261130935814\n",
      "OutKast - Hey Ya! - Radio Mix / Club Mix - 0.08831940256565037\n",
      "Rick Springfield - Jessie's Girl - 0.08788703101660567\n",
      "Vanessa Carlton - A Thousand Miles - 0.08568211967649743\n",
      "R. Kelly - Ignition - Remix - 0.08495819790551361\n",
      "Spice Girls - Wannabe - Radio Edit - 0.08369803941053391\n",
      "Lynyrd Skynyrd - Sweet Home Alabama - 0.08208312930294659\n"
     ]
    }
   ],
   "source": [
    "get_recommendations(playlist_1, co_occurences, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Pop Playlist\"\n",
    "\n",
    "playlist_2 = [\n",
    "    (\"Drake\", \"One Dance\"),\n",
    "    (\"The Chainsmokers\", \"Closer\"),\n",
    "    (\"Ed Sheeran\", \"Shape of You\"),\n",
    "    (\"Justin Bieber\", \"Sorry\"),\n",
    "    (\"The Weeknd\", \"Starboy\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major Lazer - Cold Water (feat. Justin Bieber & MØ) - 0.13594257771317855\n",
      "The Chainsmokers - Don't Let Me Down - 0.13133278571985335\n",
      "The Chainsmokers - Closer - 0.1281916074528291\n",
      "Drake - One Dance - 0.11468946249907858\n",
      "DRAM - Broccoli (feat. Lil Yachty) - 0.10871439788185103\n",
      "Mike Posner - I Took A Pill In Ibiza - Seeb Remix - 0.10678774664197961\n",
      "DJ Snake - Let Me Love You - 0.10555517322945326\n",
      "Calvin Harris - This Is What You Came For - 0.0995580318367021\n",
      "The Chainsmokers - Roses - 0.09544866523600537\n",
      "The Weeknd - Starboy - 0.09179862904217692\n"
     ]
    }
   ],
   "source": [
    "get_recommendations(playlist_2, co_occurences, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Content based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = pd.read_csv('data/song_data.csv')\n",
    "# Remove key, mode, time_signature, and duration_ms\n",
    "song_data = song_data.drop(['key', 'mode', 'time_signature', 'duration_ms'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement KNN\n",
    "\n",
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "numerical_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "X = song_data[numerical_features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre encoding\n",
    "genres = song_data[['genre']]\n",
    "encoder = OneHotEncoder()\n",
    "genres_encoded = encoder.fit_transform(genres).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine genres and numerical features and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='euclidean', n_neighbors=10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_weight = 20 # The higher the weight, the more important the genre is in the recommendation\n",
    "\n",
    "X_combined = np.concatenate((X_scaled, genres_encoded * genre_weight), axis=1)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "knn.fit(X_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define song and artist which we want to find similar songs for\n",
    "song_name = 'Boten Anna - Radio edit'\n",
    "artist_name = 'Basshunter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No song found. Check the song and artist names.\n"
     ]
    }
   ],
   "source": [
    "# Find the song in the dataset\n",
    "song_query = song_data[(song_data['track_name'].str.lower() == song_name.lower()) & (song_data['artist_name'].str.lower() == artist_name.lower())]\n",
    "\n",
    "if not song_query.empty:\n",
    "    # Scale numerical features of the query\n",
    "    song_numerical_features = scaler.transform(song_query[numerical_features])\n",
    "    \n",
    "    # Encode genre of the query\n",
    "    song_genre_encoded = encoder.transform(song_query[['genre']]).toarray()\n",
    "    \n",
    "    # Combine scaled numerical features and encoded genre for the query\n",
    "    song_combined_features = np.hstack((song_numerical_features, song_genre_encoded * 20))\n",
    "    \n",
    "    # Use KNN to find the nearest neighbors\n",
    "    distances, indices = knn.kneighbors(song_combined_features)\n",
    "    \n",
    "    print('Closest songs to |', song_name, '-', artist_name, '| are...')\n",
    "    for i in range(1, 6):\n",
    "        index = indices[0][i]\n",
    "        print('----------')\n",
    "        print(song_data.iloc[index][['track_name', 'artist_name']])\n",
    "        \n",
    "else:\n",
    "    print(\"No song found. Check the song and artist names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No song found for I'm Gonna Be (500 Miles) by The Proclaimers. Check the song and artist names.\n",
      "Closest songs to the playlist are...\n",
      "----------\n",
      "track_name     In My Room (feat. Sizzy Rocket)\n",
      "artist_name                  Young Rising Sons\n",
      "Name: 532797, dtype: object\n",
      "----------\n",
      "track_name        The Great Exhale\n",
      "artist_name    Great Lake Swimmers\n",
      "Name: 2584, dtype: object\n",
      "----------\n",
      "track_name     What's She Crying For\n",
      "artist_name      Justin Townes Earle\n",
      "Name: 255429, dtype: object\n",
      "----------\n",
      "track_name     Would You Fight For My Love?\n",
      "artist_name                      Jack White\n",
      "Name: 110131, dtype: object\n",
      "----------\n",
      "track_name     Never Be Mine\n",
      "artist_name      Angel Olsen\n",
      "Name: 215019, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "playlist_numerical_features = []\n",
    "playlist_genre_encoded = []\n",
    "recommendations_idx = []\n",
    "\n",
    "for artist_name, song_name in playlist_1:\n",
    "    song_query = song_data[(song_data['track_name'].str.lower() == song_name.lower()) & (song_data['artist_name'].str.lower() == artist_name.lower())]\n",
    "\n",
    "    if not song_query.empty:\n",
    "        # Scale numerical features of the query\n",
    "        song_numerical_features = scaler.transform(song_query[numerical_features])\n",
    "        playlist_numerical_features.append(song_numerical_features)\n",
    "        \n",
    "        # Encode genre of the query\n",
    "        song_genre_encoded = encoder.transform(song_query[['genre']]).toarray()\n",
    "        playlist_genre_encoded.append(song_genre_encoded)\n",
    "    else:\n",
    "        print(f'No song found for {song_name} by {artist_name}. Check the song and artist names.')\n",
    "\n",
    "# Aggregate features of the playlist\n",
    "if playlist_numerical_features and playlist_genre_encoded:\n",
    "\n",
    "    average_numerical_features = np.mean(np.vstack(playlist_numerical_features), axis=0)\n",
    "    average_genre_encoded = np.mean(np.vstack(playlist_genre_encoded), axis=0)\n",
    "\n",
    "    # Determine variance across the playlist for each numerical feature to use as a simple importance metric\n",
    "    variances = np.var(np.vstack(playlist_numerical_features), axis=0)\n",
    "    importance_weights = 1 / (variances + 1e-6)  \n",
    "    normalized_importance_weights = importance_weights / importance_weights.max()\n",
    "\n",
    "    # Apply weights to the aggregated playlist features\n",
    "    weighted_playlist_features = average_numerical_features * normalized_importance_weights\n",
    "\n",
    "    # Apply the same weighting to the full dataset numerical features before fitting KNN\n",
    "    weighted_numerical_features = X_scaled * normalized_importance_weights\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "    knn.fit(X_combined)\n",
    "\n",
    "    # Re-combine weighted numerical features with encoded categorical for the full dataset\n",
    "    playlist_combined_features = np.hstack([weighted_playlist_features, average_genre_encoded])\n",
    "\n",
    "    distances, indices = knn.kneighbors([playlist_combined_features])\n",
    "\n",
    "    print('Closest songs to the playlist are...')\n",
    "    for i in range(5):\n",
    "        index = indices[0][i]\n",
    "        recommendations_idx.append(index)\n",
    "        print('----------')\n",
    "        print(song_data.iloc[index][['track_name', 'artist_name']])\n",
    "else:\n",
    "    print('The playlist is empty or no songs were found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
