{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns:\n",
    "\n",
    ",artist_name,track_name,track_id,popularity,year,genre,danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo,duration_ms,time_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = pd.read_csv('data/song_data.csv')\n",
    "# Remove key, mode, time_signature, and duration_ms\n",
    "song_data = song_data.drop(['key', 'mode', 'time_signature', 'duration_ms'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement KNN\n",
    "\n",
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "numerical_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "X = song_data[numerical_features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre encoding\n",
    "genres = song_data[['genre']]\n",
    "encoder = OneHotEncoder()\n",
    "genres_encoded = encoder.fit_transform(genres).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine genres and numerical features and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='euclidean', n_neighbors=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_weight = 20 # The higher the weight, the more important the genre is in the recommendation\n",
    "\n",
    "X_combined = np.concatenate((X_scaled, genres_encoded * genre_weight), axis=1)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "knn.fit(X_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define song and artist which we want to find similar songs for\n",
    "song_name = 'What Once Was'\n",
    "artist_name = 'Her\\'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest songs to | What Once Was - Her's | are....\n",
      "----------\n",
      "track_name         Rosary\n",
      "artist_name    Inner Wave\n",
      "Name: 131030, dtype: object\n",
      "----------\n",
      "track_name              Lupa\n",
      "artist_name    King Stingray\n",
      "Name: 553167, dtype: object\n",
      "----------\n",
      "track_name     Stupid Decisions\n",
      "artist_name              FIDLAR\n",
      "Name: 180455, dtype: object\n",
      "----------\n",
      "track_name         2:00 AM\n",
      "artist_name    Los Shadows\n",
      "Name: 389334, dtype: object\n",
      "----------\n",
      "track_name     Follow The Sun\n",
      "artist_name    Royal Republic\n",
      "Name: 236101, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Find the song in the dataset\n",
    "song_query = song_data[(song_data['track_name'].str.lower() == song_name.lower()) & (song_data['artist_name'].str.lower() == artist_name.lower())]\n",
    "\n",
    "if not song_query.empty:\n",
    "    # Scale numerical features of the query\n",
    "    song_numerical_features = scaler.transform(song_query[numerical_features])\n",
    "    \n",
    "    # Encode genre of the query\n",
    "    song_genre_encoded = encoder.transform(song_query[['genre']]).toarray()\n",
    "    \n",
    "    # Combine scaled numerical features and encoded genre for the query\n",
    "    song_combined_features = np.hstack((song_numerical_features, song_genre_encoded * 20))\n",
    "    \n",
    "    # Use KNN to find the nearest neighbors\n",
    "    distances, indices = knn.kneighbors(song_combined_features)\n",
    "    \n",
    "    print('Closest songs to |', song_name, '-', artist_name, '| are...')\n",
    "    for i in range(5):\n",
    "        index = indices[0][i]\n",
    "        print('----------')\n",
    "        print(song_data.iloc[index][['track_name', 'artist_name']])\n",
    "        \n",
    "else:\n",
    "    print(\"No song found. Check the song and artist names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_test = [('What Once Was', 'Her\\'s'), \n",
    "                 ('Lauren', 'Men I Trust'),\n",
    "                 ('Pink + White', 'Frank Ocean'), \n",
    "                 ('After The Earthquake', 'Alvvays'),\n",
    "                 ('North', 'Clairo'),\n",
    "                 ('Sunflower', 'Rex Orange County'),\n",
    "                 ('Wet Dream', 'Wet Leg'),\n",
    "                 ('Freaking Out the Neighborhood', 'Mac DeMarco'),\n",
    "                 ('Lovers Rock', 'TV Girl'),\n",
    "                 ('Right Side of My Neck', 'Faye Webster'),\n",
    "                 ('Summertime Magic', 'Childish Gambino'),\n",
    "                 ('Be Sweet', 'Japanese Breakfast'),\n",
    "                 ('Where U Goin\\' Tonight?', 'Mac Ayres'),\n",
    "                 ('Just A Stranger (feat. Steve Lacy)', 'Kali Uchis'),\n",
    "                 ('Useless', 'Omar Apollo')]\n",
    "\n",
    "\n",
    "playlist_test2 = [('Easy Lover', 'Philip Bailey'),\n",
    "                  ('505', 'Arctic Monkeys'),\n",
    "                  ('Electric Feel', 'MGMT'),\n",
    "                  ('Everywhere - 2018 Remaster', 'Fleetwood Mac'),\n",
    "                  ('Blue Monday \\'88 - 2015 Remaster', 'New Order')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest songs to the playlist are...\n",
      "----------\n",
      "track_name     If You Didn't See Me (Then You Weren't on the ...\n",
      "artist_name                                                JR JR\n",
      "Name: 87707, dtype: object\n",
      "----------\n",
      "track_name     I Want It\n",
      "artist_name     Two Feet\n",
      "Name: 342922, dtype: object\n",
      "----------\n",
      "track_name     I'll Call You Mine\n",
      "artist_name           girl in red\n",
      "Name: 508586, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "playlist_numerical_features = []\n",
    "playlist_genre_encoded = []\n",
    "\n",
    "for song_name, artist_name in playlist_test:\n",
    "    song_query = song_data[(song_data['track_name'].str.lower() == song_name.lower()) & (song_data['artist_name'].str.lower() == artist_name.lower())]\n",
    "\n",
    "    if not song_query.empty:\n",
    "        # Scale numerical features of the query\n",
    "        song_numerical_features = scaler.transform(song_query[numerical_features])\n",
    "        playlist_numerical_features.append(song_numerical_features)\n",
    "        \n",
    "        # Encode genre of the query\n",
    "        song_genre_encoded = encoder.transform(song_query[['genre']]).toarray()\n",
    "        playlist_genre_encoded.append(song_genre_encoded)\n",
    "    else:\n",
    "        print(f'No song found for {song_name} by {artist_name}. Check the song and artist names.')\n",
    "\n",
    "# Aggregate features of the playlist\n",
    "if playlist_numerical_features and playlist_genre_encoded:\n",
    "    average_numerical_features = np.mean(np.vstack(playlist_numerical_features), axis=0)\n",
    "    average_genre_encoded = np.mean(np.vstack(playlist_genre_encoded), axis=0)\n",
    "\n",
    "    # Combine scaled numerical features and encoded genre for the playlist query\n",
    "    playlist_combined_features = np.hstack((average_numerical_features, average_genre_encoded * 20))\n",
    "\n",
    "    # Use KNN to find the nearest neighbors to the playlist\n",
    "    distances, indices = knn.kneighbors([playlist_combined_features])\n",
    "\n",
    "    print('Closest songs to the playlist are...')\n",
    "    for i in range(3):\n",
    "        index = indices[0][i]\n",
    "        print('----------')\n",
    "        print(song_data.iloc[index][['track_name', 'artist_name']])\n",
    "else:\n",
    "    print('The playlist is empty or no songs were found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
